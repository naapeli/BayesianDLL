import torch
import matplotlib.pyplot as plt
import numpy as np

from BayesianDLL.distributions import Normal, Beta, Exponential, Uniform, InvGamma, HalfCauchy
from BayesianDLL.sampler import NUTS


# ================== DISTRIBUTIONS IN UNRESTRICTED SPACEES ==================
plt.figure(figsize=(6, 6))
plt.subplot(3, 3, 1)
distribution = Beta(2, 2)
x = torch.linspace(-5, 5, 100)
plt.plot(x.numpy(), distribution._log_prob_unconstrained(x).numpy(), label='log_pdf')
plt.plot(x.numpy(), distribution._log_prob_grad_unconstrained(x).numpy(), label='log_pdf_grad')
plt.legend()
plt.title("Beta")

plt.subplot(3, 3, 2)
distribution = Normal(0, 1)
plt.plot(x.numpy(), distribution._log_prob_unconstrained(x).numpy(), label='log_pdf')
plt.plot(x.numpy(), distribution._log_prob_grad_unconstrained(x).numpy(), label='log_pdf_grad')
plt.legend()
plt.title("Normal")

plt.subplot(3, 3, 3)
distribution = Exponential(0.3)
plt.plot(x.numpy(), distribution._log_prob_unconstrained(x).numpy(), label='log_pdf')
plt.plot(x.numpy(), distribution._log_prob_grad_unconstrained(x).numpy(), label='log_pdf_grad')
plt.legend()
plt.title("Exponential")

plt.subplot(3, 3, 4)
distribution = Uniform(2, 5)
plt.plot(x.numpy(), distribution._log_prob_unconstrained(x).numpy(), label='log_pdf')
plt.plot(x.numpy(), distribution._log_prob_grad_unconstrained(x).numpy(), label='log_pdf_grad')
plt.legend()
plt.title("Uniform")

plt.subplot(3, 3, 5)
distribution = InvGamma(2, 2)
plt.plot(x.numpy(), distribution._log_prob_unconstrained(x).numpy(), label='log_pdf')
plt.plot(x.numpy(), distribution._log_prob_grad_unconstrained(x).numpy(), label='log_pdf_grad')
plt.legend()
plt.title("Inverse gamma")

plt.subplot(3, 3, 6)
distribution = HalfCauchy(2)
plt.plot(x.numpy(), distribution._log_prob_unconstrained(x).numpy(), label='log_pdf')
plt.plot(x.numpy(), distribution._log_prob_grad_unconstrained(x).numpy(), label='log_pdf_grad')
plt.legend()
plt.title("Half Cauchy")
plt.tight_layout()


# ================== SAMPLING ==================
n = 10000
bins = 30

plt.figure(figsize=(6, 6))
plt.subplot(3, 3, 1)
distribution = Normal(0, 1)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([0.1], dtype=torch.float64)
samples, lnprob, _ = sampler.sample(n, theta_init, 100)
plt.hist(samples.numpy(), bins=bins, alpha=0.5, density=True)
x = torch.linspace(-10, 20, 1000)
y = distribution.pdf(x)
plt.plot(x, y)
plt.title("Normal")

distribution = Normal(5, 3)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([0.1], dtype=torch.float64)
samples, _, _ = sampler.sample(n, theta_init, 100)
plt.hist(samples.numpy(), bins=bins, alpha=0.5, density=True)
x = torch.linspace(-10, 20, 1000)
y = distribution.pdf(x)
plt.plot(x, y)
plt.xlim(-5, 15)

plt.subplot(3, 3, 2)
distribution = Beta(2, 5)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([0.0], dtype=torch.float64)
samples, _, _ = sampler.sample(n, theta_init, 100)
plt.hist(samples.numpy(), bins=bins, alpha=0.5, density=True)
x = torch.linspace(0, 1, 100)
y = distribution.pdf(x)
plt.plot(x, y)
plt.title("Beta")

distribution = Beta(0.5, 0.5)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([0.0], dtype=torch.float64)
samples, _, _ = sampler.sample(n, theta_init, 100)
plt.hist(samples.numpy(), bins=bins, alpha=0.5, density=True)
x = torch.linspace(0.01, 0.99, 100)
y = distribution.pdf(x)
plt.plot(x, y)
plt.xlim(0, 1)

plt.subplot(3, 3, 3)
distribution = Exponential(0.3)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([10], dtype=torch.float64)
samples, _, _ = sampler.sample(n, theta_init, 100)
plt.hist(samples.numpy(), bins=bins, alpha=0.5, density=True)
x = torch.linspace(0, 20, 100)
y = distribution.pdf(x)
plt.plot(x, y)
plt.xlim(0, 20)
plt.title("Exponential")

plt.subplot(3, 3, 4)
distribution = Uniform(2, 5)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([10], dtype=torch.float64)
samples, _, _ = sampler.sample(n, theta_init, 100)
plt.hist(samples.numpy(), bins=bins, alpha=0.5, density=True)
x = torch.linspace(0, 7, 1000)
y = distribution.pdf(x)
plt.plot(x, y)
plt.xlim(0, 7)
plt.title("Uniform")

plt.subplot(3, 3, 5)
distribution = InvGamma(3, 6)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([0], dtype=torch.float64)
samples, lnprob, _ = sampler.sample(n, theta_init, 100)
plt.xscale("log")
plt.yscale("log")
xmin = samples.min().item()
xmax = samples.max().item()
bin_edges = np.logspace(np.log10(xmin), np.log10(xmax), bins)
plt.hist(samples.numpy(), bins=bin_edges, alpha=0.5, density=True)
x = torch.logspace(torch.log10(torch.tensor(xmin)), torch.log10(torch.tensor(xmax)), 1000)
y = distribution.pdf(x)
plt.plot(x.numpy(), y.numpy())
plt.title("Inverse gamma")

plt.subplot(3, 3, 6)
distribution = HalfCauchy(2)
sampler = NUTS(distribution._log_prob_unconstrained, distribution._log_prob_grad_unconstrained, distribution.transform.inverse)
theta_init = torch.tensor([0], dtype=torch.float64)
samples, lnprob, _ = sampler.sample(n, theta_init, 100)
plt.xscale("log")
plt.yscale("log")
xmin = samples.min().item()
xmax = samples.max().item()
bin_edges = np.logspace(np.log10(xmin), np.log10(xmax), bins)
plt.hist(samples.numpy(), bins=bin_edges, alpha=0.5, density=True)
x = torch.logspace(torch.log10(torch.tensor(xmin)), torch.log10(torch.tensor(xmax)), 1000)
y = distribution.pdf(x)
plt.plot(x.numpy(), y.numpy())
plt.title("Half Cauchy")

plt.tight_layout()
plt.show()
